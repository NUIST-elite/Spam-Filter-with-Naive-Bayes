{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spam Filter Based on Naive Bayes\n",
    "In this project, we are going to build a spam filter based on **naive bayes**.\n",
    "\n",
    "We know that computer can learn from human knowledge and classify message based on human offered probability values. As a result, our task is to \"teach\" the computer how to classify messages. To do that, we'll use the **multinomial Naive Bayes** algorithm along with a dataset of **5,572 SMS messages that are already classified by humans**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Introduction\n",
    "The data is put together by *Tiago A. Almeida and José María Gómez Hidalgo*, which can be downloaded on *The UCI Machine Learning Repository* website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import data using pandas, and naming two columns as: Label and SMS\n",
    "msgs = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "\n",
    "# Inspect the first five rows\n",
    "msgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find percentage of spam and ham\n",
    "msgs['Label'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell that about 87% of the messages are ham, and the remaining 13% are spam. This sample looks representative, since in practice most messages that people receive are not spams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set & Test Set\n",
    "Once our spam filter is done, we'll need to test how good it is with classifying new messages. To test the spam filter, we're first going to split our dataset into two categories:\n",
    "\n",
    "* A training set, which we'll use to \"train\" the computer how to classify messages.\n",
    "* A test set, which we'll use to test how good the spam filter is with classifying new messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to keep **80%(4,458 messages)** of our dataset for training, and **20%(1,114 messages)** for testing. We will use our algorithm to filter the test set, and compare it with the original human-made result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomizing the dataset\n",
    "random_msgs = msgs.sample(frac=1, random_state=1)\n",
    "\n",
    "# Calculate the index spliting the dataset\n",
    "split_index = round(len(random_msgs) * 0.8)\n",
    "\n",
    "# Split the dataset, and reset index\n",
    "train = random_msgs[:split_index].copy()\n",
    "test = random_msgs[split_index:].copy()\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the new percentage of spam and ham for both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.54105\n",
       "spam    13.45895\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set\n",
    "train['Label'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.804309\n",
       "spam    13.195691\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set\n",
    "test['Label'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ramdomizing result is satisfying in that the percentage of spam and ham messages in both dataset is similar to the origin dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Data cleaning is always an indispensable steps, and this project is not the exception likewise. Let's review our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wait.i will come out.. &amp;lt;#&amp;gt;  min:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>ham</td>\n",
       "      <td>There generally isn't one. It's an uncountable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>ham</td>\n",
       "      <td>Of course ! Don't tease me ... You know I simp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>ham</td>\n",
       "      <td>No you'll just get a headache trying to figure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pete can you please ring meive hardly gotany c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "2715   ham            Wait.i will come out.. &lt;#&gt;  min:)\n",
       "775    ham  There generally isn't one. It's an uncountable...\n",
       "117    ham  Of course ! Don't tease me ... You know I simp...\n",
       "4156   ham  No you'll just get a headache trying to figure...\n",
       "639    ham  Pete can you please ring meive hardly gotany c..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Unwanted Characters\n",
    "Because our algorithm will base one the number of times each words appear in a message, we are going split the column into single words like the form below:\n",
    "\n",
    "| Label | secret | money | my |\n",
    "| ------ | ------ | ------ | ------ |\n",
    "| spam | 2 | 1 | 0 |\n",
    "| ham | 0 | 1 | 2 |\n",
    "\n",
    "To do this, we will first remove all the punctuation, and make all letter lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>ham</td>\n",
       "      <td>wait i will come out    lt   gt   min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>ham</td>\n",
       "      <td>there generally isn t one  it s an uncountable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>ham</td>\n",
       "      <td>of course   don t tease me     you know i simp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>ham</td>\n",
       "      <td>no you ll just get a headache trying to figure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>ham</td>\n",
       "      <td>pete can you please ring meive hardly gotany c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "2715   ham            wait i will come out    lt   gt   min  \n",
       "775    ham  there generally isn t one  it s an uncountable...\n",
       "117    ham  of course   don t tease me     you know i simp...\n",
       "4156   ham  no you ll just get a headache trying to figure...\n",
       "639    ham  pete can you please ring meive hardly gotany c..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace any character that are not word.\n",
    "train['SMS'] = train['SMS'].str.replace('\\W', ' ')\n",
    "\n",
    "# Convert letter to lower case\n",
    "train['SMS'] = train['SMS'].str.lower()\n",
    "\n",
    "train.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create Vocabulary\n",
    "Next, we will extract all **unique** word in our training set to form a **vocabulary**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = []\n",
    "\n",
    "# Add each words in a row to our vocabulary list\n",
    "def add_word(elem):\n",
    "    word_list = elem.split()\n",
    "    for word in word_list:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "# Apply function to training set\n",
    "train['SMS'].apply(add_word)\n",
    "\n",
    "# Removing duplicates by converting list to set\n",
    "vocabulary = list(set(vocabulary))\n",
    "\n",
    "# Inspect length of vocabulary\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformating the Dataset\n",
    "Finally, we will use the vocabulary we acquire above to reformat the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initializing an empty dictionary like: {secret: [0,0, .... ,0]}\n",
    "word_counts_per_sms = {unique_word: [0] * len(train['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "# Iterate over the SMS column\n",
    "# For each word in each row, plus 1 to dictionary with corresponding word and index\n",
    "train['SMS'] = train['SMS'].str.split()\n",
    "for index, sms in enumerate(train['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>02072069400</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  00  000  000pes  008704050406  0089  01223585334  02  0207  02072069400  \\\n",
       "0  0   0    0       0             0     0            0   0     0            0   \n",
       "1  0   0    0       0             0     0            0   0     0            0   \n",
       "2  0   0    0       0             0     0            0   0     0            0   \n",
       "3  0   0    0       0             0     0            0   0     0            0   \n",
       "4  0   0    0       0             0     0            0   0     0            0   \n",
       "\n",
       "  ...  zindgi  zoe  zogtorius  zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "1 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "2 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "3 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "4 ...       0    0          0     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the result to a dataframe\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   ham                                           [havent]  0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334  02 ...  zindgi  zoe  zogtorius  \\\n",
       "0       0             0     0            0   0 ...       0    0          0   \n",
       "1       0             0     0            0   0 ...       0    0          0   \n",
       "2       0             0     0            0   0 ...       0    0          0   \n",
       "3       0             0     0            0   0 ...       0    0          0   \n",
       "4       0             0     0            0   0 ...       0    0          0   \n",
       "\n",
       "   zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0     0      0  0   0  0    0  0  \n",
       "1     0      0  0   0  0    0  0  \n",
       "2     0      0  0   0  0    0  0  \n",
       "3     0      0  0   0  0    0  0  \n",
       "4     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the origin training set\n",
    "train_clean = pd.concat([train, word_counts], axis=1)\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the algorithm\n",
    "After we are done with data cleaning, we can start writing the algorithm for our spam filter. First, we will review the core therom for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam) \\\\\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, considering the situation that one word only occur in one message category, we will use **Laplace Smoothing** to avoid that.\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculaing Constants\n",
    "We begin by calculating the terms that have fixed value for every message, which is as followed:\n",
    "* P(Spam) and P(Ham)\n",
    "* N<sub>Spam</sub>, <sub>NHam</sub>, <sub>NVocabulary</sub>\n",
    "\n",
    "We will calculate them using the training set we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_spam: 0.13458950201884254\n",
      "p_ham: 0.8654104979811574\n",
      "n_spam: 15190\n",
      "n_ham: 57237\n",
      "n_vocabulary: 7783\n"
     ]
    }
   ],
   "source": [
    "# P(Spam): probability that a message is a spam\n",
    "spams_num = len(train_clean[train_clean['Label'] == 'spam'])\n",
    "p_spam = spams_num / len(train_clean['Label'])\n",
    "\n",
    "# P(Ham): probability that a message is not a spam\n",
    "hams_num = len(train_clean[train_clean['Label'] == 'ham'])\n",
    "p_ham = hams_num / len(train_clean['Label'])\n",
    "\n",
    "# N<sub>Spam</sub>: total number of words in spam message\n",
    "word_per_spam_message = train_clean[train_clean['Label'] == 'spam']['SMS'].apply(len)\n",
    "n_spam = word_per_spam_message.sum()\n",
    "\n",
    "# N<sub>Ham</sub>: total number of words in non-spam message\n",
    "word_per_ham_message = train_clean[train_clean['Label'] == 'ham']['SMS'].apply(len)\n",
    "n_ham = word_per_ham_message.sum()\n",
    "\n",
    "# N<sub>Vocabulary</sub>: total number of words in vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "print('p_spam: ' + str(p_spam))\n",
    "print('p_ham: ' + str(p_ham))\n",
    "print('n_spam: ' + str(n_spam))\n",
    "print('n_ham: ' + str(n_ham))\n",
    "print('n_vocabulary: ' + str(n_vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculating Parameters\n",
    "Next, we will calculate values that are unique for every words.\n",
    "* P(w<sub>i</sub>|Spam): times the word w<sub>i</sub> appear in spam messages.\n",
    "* P(w<sub>i</sub>|Ham): times the word w<sub>i</sub> appear in non-spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Two dictionaries to store two parameters mentioned above\n",
    "p_spam_dict = {}\n",
    "p_ham_dict = {}\n",
    "\n",
    "# Isolate spam & ham messages in training set\n",
    "train_spam = train_clean[train_clean['Label'] == 'spam']\n",
    "train_ham = train_clean[train_clean['Label'] == 'ham']\n",
    "\n",
    "# Iterate over vocabulary\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = train_spam[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam + 1) / (n_spam + 1 * n_vocabulary)\n",
    "    p_spam_dict[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = train_ham[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham + 1) / (n_ham + 1 * n_vocabulary)\n",
    "    p_ham_dict[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Spam Filter Function\n",
    "Now that we've calculated all the constants and parameters we need, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "\n",
    "* Takes in as **input** a new message (w1, w2, ..., wn)\n",
    "* Calculates **P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn)**\n",
    "* Compares the values of **P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn)**, and:\n",
    "    * If P(Ham|w1, w2, ..., wn) **>** P(Spam|w1, w2, ..., wn), then the message is classified as **ham**.\n",
    "    * If P(Ham|w1, w2, ..., wn) **<** P(Spam|w1, w2, ..., wn), then the message is classified as **spam**.\n",
    "    * If P(Ham|w1, w2, ..., wn) **=** P(Spam|w1, w2, ..., wn), then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Core filter function\n",
    "def classify(message):\n",
    "    # Clean the message\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    # Initialize two parameters we will use to compare\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    # Calculate above paramters\n",
    "    for word in message:\n",
    "        if word not in vocabulary:\n",
    "            continue;\n",
    "        if word in p_spam_dict:\n",
    "            p_spam_given_message *= p_spam_dict[word]\n",
    "        if word in p_ham_dict:\n",
    "            p_ham_given_message *= p_ham_dict[word]\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "ham\n"
     ]
    }
   ],
   "source": [
    "# Roughly test it manually\n",
    "res1 = classify('Come get your prize using the link below')\n",
    "res2 = classify('I will take the money from the bank for you')\n",
    "print(res1)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our Algorithm\n",
    "Finally, we finished building the spam filter. We will test the accuracy for the algorithm using our **test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct prediction: 1100\n",
      "Incorrect prediction: 14\n",
      "Accuracy: 98.74%\n"
     ]
    }
   ],
   "source": [
    "# Variables for saving results\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "# Using a new row saving our result\n",
    "test['predict_label'] = test['SMS'].apply(classify)\n",
    "\n",
    "# Exploring the result\n",
    "for row in test.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predict_label']:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "        \n",
    "# Calculate accuracy using percentage\n",
    "accuracy = round((correct / test.shape[0]) * 100, 2)\n",
    "\n",
    "# Print the result\n",
    "print('Correct prediction: ' + str(correct))\n",
    "print('Incorrect prediction: ' + str(incorrect))\n",
    "print('Accuracy: ' + str(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "From the result we have, the accuracy of this spam filter algorithm is about 98.74%, which is a satisfying result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predict_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ham</td>\n",
       "      <td>Unlimited texts. Limited minutes.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ham</td>\n",
       "      <td>26th OF JULY</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                                SMS  \\\n",
       "114  spam  Not heard from U4 a while. Call me now am here...   \n",
       "135  spam  More people are dogging in your area now. Call...   \n",
       "152   ham                  Unlimited texts. Limited minutes.   \n",
       "159   ham                                       26th OF JULY   \n",
       "284   ham                             Nokia phone is lovly..   \n",
       "293   ham  A Boy loved a gal. He propsd bt she didnt mind...   \n",
       "302   ham                   No calls..messages..missed calls   \n",
       "319   ham  We have sent JD for Customer Service cum Accou...   \n",
       "504  spam  Oh my god! I've found your number again! I'm s...   \n",
       "546  spam  Hi babe its Chloe, how r u? I was smashed on s...   \n",
       "741  spam  0A$NETWORKS allow companies to bill for SMS, s...   \n",
       "876  spam           RCT' THNQ Adrian for U text. Rgds Vatian   \n",
       "885  spam                                      2/2 146tf150p   \n",
       "953  spam  Hello. We need some posh birds and chaps to us...   \n",
       "\n",
       "                  predict_label  \n",
       "114                         ham  \n",
       "135                         ham  \n",
       "152                        spam  \n",
       "159                        spam  \n",
       "284                        spam  \n",
       "293  needs human classification  \n",
       "302                        spam  \n",
       "319                        spam  \n",
       "504                         ham  \n",
       "546                         ham  \n",
       "741                         ham  \n",
       "876                         ham  \n",
       "885                         ham  \n",
       "953                         ham  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the incorrect prediction\n",
    "test[test['Label'] != test['predict_label']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
